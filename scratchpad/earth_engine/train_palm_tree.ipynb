{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import apache_beam as beam\n",
    "from typing import Dict, List, Tuple\n",
    "import numpy as np\n",
    "\n",
    "import distinctipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # To achieve good shuffling, each label should be in its own file\n",
    "# # The function will take one sample from each label (i.e. file) and then shuffle them\n",
    "# def load_dataset(filenames: List[str], deserialization_function, number_of_files):\n",
    "#     parallel_reads = len(filenames)\n",
    "    \n",
    "#     files = tf.data.Dataset.from_tensor_slices(filenames)\n",
    "\n",
    "#     ds = files.interleave(lambda x: tf.data.TFRecordDataset(x), \n",
    "#                           cycle_length=len(filenames), \n",
    "#                           block_length=1,\n",
    "#                           num_parallel_calls=tf.data.experimental.AUTOTUNE,\n",
    "#                           deterministic=False)\n",
    "\n",
    "#     ds = ds.flat_map(lambda x : deserialization_function(x, number_of_files))  # parse the record\n",
    "#     ds = ds.shuffle(parallel_reads, reshuffle_each_iteration=True)\n",
    "\n",
    "#     return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# palette = [\n",
    "# '000000', # 0 No Data\n",
    "# 'a6cee3', # 1 Water\n",
    "# '1f78b4', # 2 Opaque Clouds\n",
    "# 'b2df8a', # 3 Trees and Shrubs\n",
    "# '33a02c', # 4 Built surface\n",
    "# 'fb9a99', # 5 Bridges and dams\n",
    "# 'e31a1c', # 6 Grass\n",
    "# 'fdbf6f', # 7 Plant/Ground Mix\n",
    "# 'ff7f00', # 8 Crops (other than Palm Plantations)\n",
    "# 'cab2d6', # 9 Palm Plantations\n",
    "# '6a3d9a', # 10 Flooded Vegetation\n",
    "# 'ffff99', # 11 Bare Ground and Sand\n",
    "# 'b15928', # 12 Snow and Ice\n",
    "# '000000'  # 13 Unknown\n",
    "# ]\n",
    "\n",
    "CLASSIFICATIONS = {\n",
    "  \"No data\": '000000',\n",
    "  \"Water\": 'a6cee3',\n",
    "  \"Opaque Clouds\": '1f78b4',\n",
    "  \"Trees and Shrubs\": 'b2df8a',\n",
    "  \"Built surface\": '33a02c',\n",
    "  \"Bridges and dams\": 'fb9a99',\n",
    "  \"Grass\": 'e31a1c',\n",
    "  \"Plant/Ground Mix\": 'fdbf6f',\n",
    "  \"Crops (other than Palm Plantations)\": 'ff7f00',\n",
    "  \"Palm Plantations\": 'cab2d6',\n",
    "  \"Flooded Vegetation\": '6a3d9a',\n",
    "  \"Bare Ground and Sand\": 'ffff99',\n",
    "  \"Snow and Ice\": 'b15928',\n",
    "  \"Unknown\": '000000'\n",
    "}\n",
    "\n",
    "NUM_CLASSES = len(CLASSIFICATIONS)\n",
    "\n",
    "# Each tile is from 30cm WV3 satellite imagery, is 1024px x 1024px and is labelled twice.\n",
    "SCALE = 0.3\n",
    "PATCH_SIZE = 512\n",
    "\n",
    "INPUT_BANDS = ['R', 'G', 'B']\n",
    "LABELS_NAMES = ['label_1', 'label_2']\n",
    "FEATURES = INPUT_BANDS + LABELS_NAMES\n",
    "\n",
    "IMG_SIZE = [PATCH_SIZE, PATCH_SIZE, len(INPUT_BANDS)]\n",
    "\n",
    "# Specify the size and shape of patches expected by the model.\n",
    "KERNEL_SHAPE = [PATCH_SIZE, PATCH_SIZE]\n",
    "COLUMNS = [\n",
    "  tf.io.FixedLenFeature(shape=KERNEL_SHAPE, dtype=tf.float32) for k in FEATURES\n",
    "]\n",
    "FEATURES_DICT = dict(zip(FEATURES, COLUMNS))\n",
    "\n",
    "def parse_tfrecord(example_proto):\n",
    "  \"\"\"The parsing function.\n",
    "  Read a serialized example into the structure defined by FEATURES_DICT.\n",
    "  Args:\n",
    "    example_proto: a serialized Example.\n",
    "  Returns:\n",
    "    A dictionary of tensors, keyed by feature name.\n",
    "  \"\"\"\n",
    "  return tf.io.parse_single_example(example_proto, FEATURES_DICT)\n",
    "\n",
    "\n",
    "def to_tuple(tensor):\n",
    "  \"\"\"Function to convert a tensor to a tuple of (inputs, outputs).\n",
    "  Args:\n",
    "    tensor: A stacked tensor, with label last.\n",
    "  Returns:\n",
    "    A tuple of (inputs, outputs).\n",
    "  \"\"\"\n",
    "  # return tensor[:,:,:len(BANDS)], tensor[:,:,len(BANDS):]\n",
    "  return {\n",
    "    \"R\": tensor[:, :, 0],\n",
    "    \"G\": tensor[:, :, 1],\n",
    "    \"B\": tensor[:, :, 2]\n",
    "  }\n",
    "\n",
    "\n",
    "def flatten_patches(inputs):\n",
    "  \"\"\"Function to convert a dictionary of tensors to two stacked \n",
    "    tensors in HWC shape.\n",
    "  Args:\n",
    "    inputs: A dictionary of tensors, keyed by feature name.\n",
    "  Returns:\n",
    "    A tf.data.Dataset with two examaples in it.\n",
    "  \"\"\"\n",
    "  # inputsList = [inputs.get(key) for key in BANDS]\n",
    "  # label_1 = [inputs.get(LABELS_NAMES[0])]\n",
    "  # label_2 = [inputs.get(LABELS_NAMES[1])]\n",
    "  # stack1 = tf.stack(inputsList + label_1, axis=0)\n",
    "  # stack2 = tf.stack(inputsList + label_2, axis=0)\n",
    "  # # Convert from CHW to HWC\n",
    "  # return tf.data.Dataset.from_tensor_slices([\n",
    "  #   tf.transpose(stack1, [1, 2, 0]),\n",
    "  #   tf.transpose(stack2, [1, 2, 0]),\n",
    "  # ])\n",
    "  \n",
    "  bands = {key: inputs.get(key) for key in INPUT_BANDS}\n",
    "  \n",
    "  # return tf.data.Dataset.from_tensor_slices([{**bands, **{label_name: inputs.get(label_name)}} for label_name in LABELS_NAMES])\n",
    "  # return tf.data.Dataset.from_tensor_slices([{\"a\": \"A\"}, {\"b\": \"B\"}]) #tf.data.Dataset.from_tensor_slices((bands, bands))\n",
    "  # return [{**bands, **{label_name: inputs.get(label_name)}} for label_name in LABELS_NAMES]\n",
    "  return {**bands, **{LABELS_NAMES[0]: inputs.get(LABELS_NAMES[0])}}\n",
    "\n",
    "def preprocess(values: Dict[str, tf.Tensor]) -> Tuple[Dict[str, tf.Tensor], tf.Tensor]:\n",
    "  # Create a dictionary of band values.\n",
    "  inputs = {name: values[name] for name in INPUT_BANDS}\n",
    "\n",
    "  # Convert the labels into one-hot encoded vectors.\n",
    "  outputs = tf.one_hot(tf.cast(values[\"label_1\"], tf.uint8), len(CLASSIFICATIONS))\n",
    "  return (inputs, outputs)\n",
    "\n",
    "def get_dataset(glob):\n",
    "  \"\"\"\"\"\"\n",
    "  dataset = tf.data.TFRecordDataset(glob, compression_type='GZIP')\n",
    "  dataset = dataset.map(parse_tfrecord, num_parallel_calls=5)\n",
    "  # dataset = dataset.map(flatten_patches)\n",
    "  # dataset = dataset.map(to_tuple, num_parallel_calls=5)\n",
    "  dataset = dataset.map(preprocess)\n",
    "\n",
    "  return dataset\n",
    "\n",
    "\n",
    "def get_datasets(pattern):\n",
    "    \"\"\"\"\"\"\n",
    "    glob = tf.io.gfile.glob(pattern)\n",
    "    size = len(glob)\n",
    "    print(f\"size: {size}\")\n",
    "    train_size = int(0.8*size)\n",
    "    shuffled = tf.random.shuffle(glob)\n",
    "    train_files = shuffled[:train_size]\n",
    "    test_files = shuffled[train_size:]\n",
    "    training = get_dataset(train_files) #.take(24)\n",
    "    training = training.batch(16)\n",
    "    # training = training.shuffle(2048).repeat()\n",
    "    testing = get_dataset(test_files) #.take(24)\n",
    "    testing = testing.batch(16)\n",
    "    return training, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 2014\n"
     ]
    }
   ],
   "source": [
    "pattern = \"gs://ivanmkc-palm-data-2/high-res-patches/labels_*.tfrecord.gz\"\n",
    "\n",
    "training_dataset, testing_dataset = get_datasets(pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(list(testing_dataset.as_numpy_iterator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for item in training_dataset.take(1).as_numpy_iterator():\n",
    "#     print(item)\n",
    "\n",
    "# items = list(testing_dataset.take(2).as_numpy_iterator())\n",
    "# item = items[0]\n",
    "\n",
    "# image = np.stack([item['R'], item['G'], item['B']], 2)\n",
    "# mask = np.stack([item['label_1']], 2)\n",
    "\n",
    "# np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def display_image_mask(image, mask):\n",
    "#   plt.figure(figsize=(15, 15))\n",
    "\n",
    "#   title = ['Input Image', 'True Mask']\n",
    "\n",
    "#   display_list = [image, mask]\n",
    "\n",
    "#   for i in range(len(display_list)):\n",
    "#     plt.subplot(1, len(display_list), i+1)\n",
    "#     plt.title(title[i])\n",
    "#     plt.imshow(tf.keras.utils.array_to_img(display_list[i]))\n",
    "#     plt.axis('off')\n",
    "#   plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display_image_mask(image, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, value in item.items():\n",
    "#     print(f\"{name}: {value.dtype.name} {value.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.unique(item['label_2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'R': <KerasTensor: shape=(None, None, None) dtype=float32 (created by layer 'R')>,\n",
       " 'G': <KerasTensor: shape=(None, None, None) dtype=float32 (created by layer 'G')>,\n",
       " 'B': <KerasTensor: shape=(None, None, None) dtype=float32 (created by layer 'B')>}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "input_layers = {\n",
    "    name: tf.keras.Input(shape=(None, None), name=name)\n",
    "    for name in INPUT_BANDS\n",
    "}\n",
    "input_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"FullyConvolutionalNetwork\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Normalize (Normalization)    (None, None, None, 3)     7         \n",
      "_________________________________________________________________\n",
      "Conv2D (Conv2D)              (None, None, None, 32)    2432      \n",
      "_________________________________________________________________\n",
      "Deconv2D (Conv2DTranspose)   (None, None, None, 16)    12816     \n",
      "_________________________________________________________________\n",
      "LandCover (Dense)            (None, None, None, 14)    238       \n",
      "=================================================================\n",
      "Total params: 15,493\n",
      "Trainable params: 15,486\n",
      "Non-trainable params: 7\n",
      "_________________________________________________________________\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# Adapt the Normalization layer with the training dataset.\n",
    "normalization = tf.keras.layers.Normalization(name=\"Normalize\")\n",
    "normalization.adapt(\n",
    "    training_dataset.map(\n",
    "        lambda inputs, _: tf.stack([inputs[name] for name in INPUT_BANDS], axis=-1)\n",
    "    )\n",
    ")\n",
    "\n",
    "# Define the Fully Convolutional Network.\n",
    "fcn_model = tf.keras.Sequential([\n",
    "    tf.keras.Input(shape=(None, None, len(INPUT_BANDS)), name=\"Inputs\"),\n",
    "    normalization,\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", name=\"Conv2D\"),\n",
    "    tf.keras.layers.Conv2DTranspose(filters=16, kernel_size=5, activation=\"relu\", name=\"Deconv2D\"),\n",
    "    tf.keras.layers.Dense(len(CLASSIFICATIONS), activation=\"softmax\", name=\"LandCover\"),\n",
    "], name=\"FullyConvolutionalNetwork\")\n",
    "\n",
    "fcn_model.summary()\n",
    "tf.keras.utils.plot_model(fcn_model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "# Define the input dictionary layers.\n",
    "input_layers = {\n",
    "    name: tf.keras.Input(shape=(None, None, 1), name=name)\n",
    "    for name in INPUT_BANDS\n",
    "}\n",
    "\n",
    "# Model wrapper that takes an input dictionary and feeds it to the FCN.\n",
    "inputs = tf.keras.layers.concatenate(input_layers.values(), name=\"Stack\")\n",
    "model = tf.keras.Model(input_layers, fcn_model(inputs), name=\"land_cover_classifier\")\n",
    "\n",
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-13 08:55:29.702979: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:175] Filling up shuffle buffer (this may take a while): 9 of 10\n",
      "2022-05-13 08:55:30.006484: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:228] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   1145/Unknown - 7698s 7s/step - loss: 1.9997 - accuracy: 0.3472"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/0d/kr5xxsl171x_0fqry12b_3hh00rmmq/T/ipykernel_18707/3189780822.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Train the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m model.fit(\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtraining_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtesting_dataset\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/mineral/env/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1182\u001b[0m                 _r=1):\n\u001b[1;32m   1183\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/mineral/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/mineral/env/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 917\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    918\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    919\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/mineral/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/mineral/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/Documents/code/mineral/env/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/code/mineral/env/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Train the model.\n",
    "model.fit(\n",
    "    training_dataset.shuffle(10),\n",
    "    validation_data=testing_dataset,\n",
    "    epochs=15,\n",
    ")\n",
    "\n",
    "# Save it as files.\n",
    "model.save(\"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3f6280b32b24df617ee52bc9a54f5fd43d751c5bddace2cefb1417d94c3321df"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
